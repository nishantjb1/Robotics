{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.14.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Downloading xmltodict-0.14.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xmltodict\n",
    "import glob\n",
    "\n",
    "# Define paths to your dataset\n",
    "images_path = 'Dataset/cardboard_images'\n",
    "annotations_path = 'Dataset/cardboard_annotation'\n",
    "\n",
    "# Class name mapping (YOLO format uses numeric IDs, so map 'cardboard' to 0)\n",
    "class_name_to_id = {'cardboard': 0}\n",
    "\n",
    "def convert_voc_to_yolo(xml_file, output_txt_path, image_size):\n",
    "    # Parse XML annotation\n",
    "    with open(xml_file) as f:\n",
    "        xml_content = xmltodict.parse(f.read())\n",
    "\n",
    "    image_width = image_size[0]\n",
    "    image_height = image_size[1]\n",
    "\n",
    "    # Check if the XML file contains any object\n",
    "    if 'object' not in xml_content['annotation']:\n",
    "        return\n",
    "\n",
    "    # Open the output text file for YOLO labels\n",
    "    with open(output_txt_path, 'w') as txt_file:\n",
    "        # Handle single or multiple objects\n",
    "        objects = xml_content['annotation']['object']\n",
    "        if isinstance(objects, dict):\n",
    "            objects = [objects]  # Convert single object to list for consistency\n",
    "\n",
    "        for obj in objects:\n",
    "            class_name = obj['name']\n",
    "            class_id = class_name_to_id.get(class_name)\n",
    "\n",
    "            if class_id is None:\n",
    "                print(f\"Warning: Class '{class_name}' not found in class map.\")\n",
    "                continue\n",
    "\n",
    "            # Extract the bounding box and normalize coordinates\n",
    "            bbox = obj['bndbox']\n",
    "            xmin = int(bbox['xmin'])\n",
    "            ymin = int(bbox['ymin'])\n",
    "            xmax = int(bbox['xmax'])\n",
    "            ymax = int(bbox['ymax'])\n",
    "\n",
    "            # YOLO format requires normalized center coordinates and width/height\n",
    "            x_center = ((xmin + xmax) / 2) / image_width\n",
    "            y_center = ((ymin + ymax) / 2) / image_height\n",
    "            width = (xmax - xmin) / image_width\n",
    "            height = (ymax - ymin) / image_height\n",
    "\n",
    "            # Write to the txt file in YOLO format\n",
    "            txt_file.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Process all XML annotations and convert them to YOLO format\n",
    "def convert_dataset(annotations_folder, images_folder):\n",
    "    for split in ['train', 'val']:\n",
    "        xml_files = glob.glob(f'{annotations_folder}/{split}/*.xml')\n",
    "        os.makedirs(f'{images_folder}/labels/{split}', exist_ok=True)\n",
    "\n",
    "        for xml_file in xml_files:\n",
    "            # Extract image size from the XML annotation\n",
    "            with open(xml_file) as f:\n",
    "                xml_content = xmltodict.parse(f.read())\n",
    "                image_width = int(xml_content['annotation']['size']['width'])\n",
    "                image_height = int(xml_content['annotation']['size']['height'])\n",
    "            # Create the output txt path\n",
    "            image_filename = os.path.basename(xml_file).replace('.xml', '.jpg')\n",
    "            txt_output_path = f'{images_folder}/labels/{split}/{image_filename.replace(\".jpg\", \".txt\")}'\n",
    "\n",
    "            # Convert and save the YOLO label\n",
    "            convert_voc_to_yolo(xml_file, txt_output_path, (image_width, image_height))\n",
    "\n",
    "# Run the conversion for the train and val sets\n",
    "convert_dataset(annotations_path, images_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python38\\python.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'c:\\Program' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!{sys.executable} -m pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Define augmentation pipeline\n",
    "augmentor = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.1),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Rotate(limit=15, p=0.5),  # Rotate by Â±15 degrees\n",
    "    A.Resize(640, 640)  # Resize all images to 640x640\n",
    "], bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "# Folder paths\n",
    "input_images_folder = 'Dataset/cardboard_images/train'  # Path to your training images\n",
    "input_labels_folder = 'Dataset/cardboard_images/labels/train'  # Path to your training labels\n",
    "output_images_folder = 'Augmented_Data/images/train'  # Augmented images folder\n",
    "output_labels_folder = 'Augmented_Data/labels/train'  # Augmented labels folder\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(output_images_folder, exist_ok=True)\n",
    "os.makedirs(output_labels_folder, exist_ok=True)\n",
    "\n",
    "# Function to read YOLO labels\n",
    "def read_yolo_label(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        bboxes = []\n",
    "        class_labels = []\n",
    "        for line in f.readlines():\n",
    "            line = line.strip().split()\n",
    "            class_id = int(line[0])\n",
    "            bbox = [float(x) for x in line[1:]]\n",
    "            bboxes.append(bbox)\n",
    "            class_labels.append(class_id)\n",
    "    return bboxes, class_labels\n",
    "\n",
    "# Function to save augmented YOLO labels\n",
    "def save_yolo_label(label_path, bboxes, class_labels):\n",
    "    with open(label_path, 'w') as f:\n",
    "        for bbox, class_id in zip(bboxes, class_labels):\n",
    "            bbox_str = ' '.join([str(x) for x in bbox])\n",
    "            f.write(f'{class_id} {bbox_str}\\n')\n",
    "\n",
    "# Loop through all images and labels in the dataset and apply augmentations\n",
    "for image_file in os.listdir(input_images_folder):\n",
    "    if image_file.endswith('.jpg'):\n",
    "        # Read image\n",
    "        img_path = os.path.join(input_images_folder, image_file)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # Read corresponding label\n",
    "        label_file = image_file.replace('.jpg', '.txt')\n",
    "        label_path = os.path.join(input_labels_folder, label_file)\n",
    "        bboxes, class_labels = read_yolo_label(label_path)\n",
    "\n",
    "        # Apply augmentation\n",
    "        augmented = augmentor(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_bboxes = augmented['bboxes']\n",
    "        augmented_class_labels = augmented['class_labels']\n",
    "\n",
    "        # Save augmented image and label\n",
    "        output_image_path = os.path.join(output_images_folder, f'aug_{image_file}')\n",
    "        output_label_path = os.path.join(output_labels_folder, f'aug_{label_file}')\n",
    "        cv2.imwrite(output_image_path, augmented_image)\n",
    "        save_yolo_label(output_label_path, augmented_bboxes, augmented_class_labels)\n",
    "\n",
    "print(\"Data augmentation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
